---
title: "time_series_analysis"
output: html_document
---

(SUMMARY HERE)


```{r setup, include=FALSE, eval = FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(xts)
library(lubridate)
```

##Time Series Analysis in R
Exploring daily sales data of software firm 1C. This dataset was obtained from Kaggle and is used for the final project of the Coursera "How to win a data science competition" coutse.  NOTE: I did not take this course!

First to import the data and see how it looks:


```{r import}
#train data
train <- read.csv('data/train.csv', stringsAsFactors = FALSE)

#test data & Kaggle sample sub
test <- read.csv('data/test.csv')
sample_sub <- read.csv('data/sample_submission.csv')

#additional data included
items <- read.csv('data/items.csv')
categories <- read.csv('data/item_categories.csv')
shops <- read.csv("data/shops.csv")
```

## Describe the datasets

Initial exploration to check data types, sizes, etc. 

```{r explore}
dim(train)
head(train)

dim(test)
head(test)

head(sample_sub)

```

So, looks as if we're to predict the 'item_cnt_month' based upon 'shop_id' and 'item_id'.. A few things this informs us:

Need to craft a 'daily sales'item_cnt_day' varible in the train set into a monthly sale count to have an appropriate dependant variable for model fitting. This should be done by  
  
  -Aggregate daily sales into monthy, split by shop_id and item_id.

Once this is done, we have two other variables of interest in the train:
  -date :  we'll perform some time-series analysis here
  -price: I'm, sure there is some coreelation between this and monthly sales.
  
So, first step is to create the monthly sales variable in train per shop/item. Then we can explore trends and seasonality in the time-series.

```{r set_dependent}
#First set year variable and edit typeas
train$year <- substr(train$date, 7, 10)
train$year <- as.numeric(train$year)

train$month <- substr(train$date, 4, 5)
train$month <- as.numeric(train$month)

train$date <- as.Date(train$date, "%d.%m.%Y")

sapply(train, class)
```

Should have done this first probably :/  lets check for missing values real quick.

```{r}
sapply(train, function(x) sum(is.na(x)))

```

Love Kaggle for that.  Lets divert from the train for a second and add the next block count, year, and month to the test set.  We know it's the next year/month occuring right after the end of the train set, which is october 2015.

```{r}
date <- as.Date("01.11.2015", "%d.%m.%Y")

for (i in 1:nrow(test)){
  test[i,4] = 35
  test[i, 5] = 2015
  test[i, 6] = 11
}

colnames(test)[4:6] <- c('date_block_num', 'year', 'month')

```

So we have a train dataset of 'train_month' and test is updated with necessary information. While I imagine we could work on feature generation or bring in the category/item datasets here to add accuracy to the fit, I'm going to focus on normalizing the time-series first and picking our trend/seasonality. 
```{r, eval = FALSE}
#train$my <- floor_date(train$date, "month")

df_train <- train %>% group_by(date_block_num, shop_id, item_id, year, month) %>% 
  summarize(item_cnt_month = sum(item_cnt_day)) 

```

##kill me

```{r}
basic <- df_train %>% group_by(shop_id, item_id) %>% 
  summarize(mean_count = median(item_cnt_month)) 


overall_mean <- mean(basic$mean_count)

basic_test <- test %>% select(ID, shop_id, item_id)

basic_test <- merge(x = basic_test, y = basic, by = c("shop_id", "item_id"), all.x = TRUE)
basic_test$mean_count[is.na(basic_test$mean_count)] <- overall_mean

preds = basic_test$mean_count
sample_sub$item_cnt_month = preds

write.csv(sample_sub, file = "D://projects/kaggle/time_series/basic_af.csv", row.names = FALSE)
```
